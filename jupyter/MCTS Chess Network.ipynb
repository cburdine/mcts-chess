{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ada7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:13:45.492015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-21 16:13:45.492035: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c620c",
   "metadata": {},
   "source": [
    "## MCTS Chess Neural Network\n",
    "---\n",
    "\n",
    "[notes go here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe4a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "class SimpleChessNet(Model):\n",
    "    \n",
    "    def __init__(self, action_size,\n",
    "                 board_input_shape=(8,8,6),\n",
    "                 n_conv_channels=12,\n",
    "                 dropout_rate=0.5):\n",
    "        \n",
    "        super(SimpleChessNet, self).__init__()\n",
    "        \n",
    "        self.board_x, self.board_y, self.board_channels = board_input_shape\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.input_layer = Input(shape=board_input_shape)\n",
    "        \n",
    "        h_conv1 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(self.input_layer))) # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(h_conv1)))          # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv2)))         # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv3)))         # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)\n",
    "        \n",
    "        s_fc1 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        \n",
    "        # get the policy and value estimates:\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2) # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)\n",
    "        \n",
    "        self.model = Model(inputs=self.input_layer, outputs=[self.pi, self.v])\n",
    "        # self.model.compile(loss=['categorical_crossentropy', 'mean_squared_error'], optimizer=Adam(learning_rate))\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def compute_loss(self, x, pi, v):\n",
    "        policy_pred, v_pred = self.__call__(x)\n",
    "        v_loss = tf.reduce_mean((v_pred - v)**2)\n",
    "        pi_loss = tf.reduce_mean(-pi*tf.math.log(policy_pred))\n",
    "        total_loss = tf.add_n([(v_loss + pi_loss)] + self.losses) \n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self.model, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e41a68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8, 8, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 8, 12)     648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 8, 12)     48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8, 8, 12)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 12)     1296        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 12)     48          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 12)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 6, 6, 12)     1296        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 12)     48          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 6, 6, 12)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 12)     1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 4, 12)     48          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 12)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 192)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         196608      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524288      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pi (Dense)                      (None, 4096)         2101248     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            513         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,833,529\n",
      "Trainable params: 2,830,361\n",
      "Non-trainable params: 3,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:13:46.998778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-21 16:13:46.998813: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-21 16:13:46.998837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcturus): /proc/driver/nvidia/version does not exist\n",
      "2021-12-21 16:13:46.999134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleChessNet(action_size=64*64)\n",
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "class ChessNetModule(tf.Module):\n",
    "    \n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super(ChessNetModule, self).__init__()\n",
    "        self.model = SimpleChessNet(action_size=64*64)\n",
    "        self.optimizer = Adam(learning_rate)\n",
    "                \n",
    "        \n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6])])\n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6], tf.float32), \n",
    "                                  tf.TensorSpec([None,64*64], tf.float32), \n",
    "                                  tf.TensorSpec([None], tf.float32)])\n",
    "    def train_step(self, x, pi, v):\n",
    "        with tf.GradientTape() as tape:\n",
    "            v_loss, pi_loss, total_loss = self.model.compute_loss(x, pi, v)\n",
    "        \n",
    "        grads = tape.gradient(total_loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self, path, \n",
    "        signatures={\n",
    "            'chessnet_serve' : \n",
    "                self.__call__.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32)),\n",
    "            'chessnet_train' : \n",
    "                self.train_step.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32),\n",
    "                                                      tf.TensorSpec([None,64*64], tf.float32),\n",
    "                                                      tf.TensorSpec([None], tf.float32))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e92ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SimpleChessNet object at 0x7fa0e45fc550>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:13:48.730096: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple_chess_net/assets\n"
     ]
    }
   ],
   "source": [
    "nn_mod = ChessNetModule()\n",
    "nn_mod.save('simple_chess_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41118c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

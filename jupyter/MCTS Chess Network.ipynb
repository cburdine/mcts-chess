{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ada7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 21:33:37.388528: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 21:33:37.424923: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-09 21:33:37.424960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-09 21:33:37.425933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-09 21:33:37.431660: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 21:33:37.432090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 21:33:38.417597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hindu-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "print('TF Version:', tf.__version__)\n",
    "# Should work with TF 2.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c620c",
   "metadata": {},
   "source": [
    "## MCTS Chess Neural Network\n",
    "---\n",
    "\n",
    "[notes go here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe4a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "class SimpleChessNet(Model):\n",
    "    \n",
    "    def __init__(self, action_size,\n",
    "                 board_input_shape=(8,8,6),\n",
    "                 n_conv_channels=12,\n",
    "                 dropout_rate=0.5,\n",
    "                 pi_weight=300.0):\n",
    "        \n",
    "        super(SimpleChessNet, self).__init__()\n",
    "        \n",
    "        self.board_x, self.board_y, self.board_channels = board_input_shape\n",
    "        self.action_size = action_size\n",
    "        self.pi_weight = tf.constant(pi_weight)\n",
    "        \n",
    "        self.input_layer = Input(shape=board_input_shape)\n",
    "        \n",
    "        \n",
    "        h_conv1 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(self.input_layer))) # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(h_conv1)))          # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv2)))         # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv3)))         # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)\n",
    "        \n",
    "        s_fc1 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        \n",
    "        # get the policy and value estimates:\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2) # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)\n",
    "        \n",
    "        self.model = Model(inputs=self.input_layer, outputs=[self.pi, self.v])\n",
    "        # self.model.compile(loss=['categorical_crossentropy', 'mean_squared_error'], optimizer=Adam(learning_rate))\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def compute_loss(self, x, pi, v):\n",
    "        policy_pred, v_pred = self.__call__(x)\n",
    "        v_loss = tf.reduce_mean((v_pred - v)**2)\n",
    "        pi_loss = tf.reduce_mean(-pi*tf.math.log(policy_pred))\n",
    "        total_loss = v_loss + self.pi_weight*pi_loss #tf.add_n([(v_loss + pi_loss)] + self.losses)\n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self.model, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e41a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 8, 6)]            0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 8, 8, 12)             648       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 8, 8, 12)             48        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 8, 8, 12)             0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 12)             1296      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 12)             48        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 8, 8, 12)             0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 12)             1296      ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 6, 6, 12)             48        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 6, 6, 12)             0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 12)             1296      ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 4, 4, 12)             48        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 4, 4, 12)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 192)                  0         ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 196608    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 1024)                 4096      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 1024)                 0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 512)                  524288    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 512)                  2048      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 512)                  0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " pi (Dense)                  (None, 4096)                 2101248   ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " v (Dense)                   (None, 1)                    513       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2833529 (10.81 MB)\n",
      "Trainable params: 2830361 (10.80 MB)\n",
      "Non-trainable params: 3168 (12.38 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleChessNet(action_size=64*64)\n",
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "class ChessNetModule(tf.Module):\n",
    "    \n",
    "    def __init__(self, learning_rate=1e-5):\n",
    "        super(ChessNetModule, self).__init__()\n",
    "        self.model = SimpleChessNet(action_size=64*64)\n",
    "        self.optimizer = Adam(learning_rate)\n",
    "        self.checkpoint = tf.train.Checkpoint(self.model)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6])])\n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6], tf.float32), \n",
    "                                  tf.TensorSpec([None,64*64], tf.float32), \n",
    "                                  tf.TensorSpec([None], tf.float32)])\n",
    "    def train_step(self, x, pi, v):\n",
    "        with tf.GradientTape() as tape:\n",
    "            v_loss, pi_loss, total_loss = self.model.compute_loss(x, pi, v)\n",
    "        \n",
    "        grads = tape.gradient(total_loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6], tf.float32), \n",
    "                                  tf.TensorSpec([None,64*64], tf.float32), \n",
    "                                  tf.TensorSpec([None], tf.float32)])\n",
    "    def validate_step(self, x, pi, v):\n",
    "            v_loss, pi_loss, total_loss = self.model.compute_loss(x, pi, v)\n",
    "            return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.string)])\n",
    "    def save_checkpoint(self, path):\n",
    "        self.checkpoint.write(path)\n",
    "        return path\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.string)])\n",
    "    def reset_optimizer(self, options):\n",
    "        for var in self.optimizer.variables:\n",
    "            var.assign(tf.zeros_like(var))\n",
    "\n",
    "        return options\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self, path, \n",
    "        signatures={\n",
    "            'chessnet_serve' : \n",
    "                self.__call__.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32)),\n",
    "            'chessnet_train' : \n",
    "                self.train_step.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32),\n",
    "                                                      tf.TensorSpec([None,64*64], tf.float32),\n",
    "                                                      tf.TensorSpec([None], tf.float32)),\n",
    "            'chessnet_validate' : \n",
    "                self.validate_step.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32),\n",
    "                                                      tf.TensorSpec([None,64*64], tf.float32),\n",
    "                                                      tf.TensorSpec([None], tf.float32)),\n",
    "            'chessnet_save_checkpoint':\n",
    "               self.save_checkpoint.get_concrete_function(tf.TensorSpec([], tf.string)),\n",
    "            'chessnet_reset_optimizer':\n",
    "               self.reset_optimizer.get_concrete_function(tf.TensorSpec([], tf.string)),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e92ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 4096), dtype=float32, numpy=\n",
      "array([[0.00023931, 0.00025386, 0.00024758, ..., 0.00023651, 0.00027289,\n",
      "        0.00023098]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.18545932]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "nn_mod = ChessNetModule()\n",
    "\n",
    "x_test = tf.random.uniform(shape=[1,8,8,6])\n",
    "print(nn_mod(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a41118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SimpleChessNet object at 0x7fc620140430>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SimpleChessNet object at 0x7fc620140430>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple_chess_net_v3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple_chess_net_v3/assets\n"
     ]
    }
   ],
   "source": [
    "nn_mod.save('simple_chess_net_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de14ab5-4577-4a45-9808-11d7e68da243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

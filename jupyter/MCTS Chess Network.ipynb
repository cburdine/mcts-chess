{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ada7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 18:53:07.591605: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-20 18:53:07.591674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hindu-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "print('TF Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c620c",
   "metadata": {},
   "source": [
    "## MCTS Chess Neural Network\n",
    "---\n",
    "\n",
    "[notes go here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe4a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "class SimpleChessNet(Model):\n",
    "    \n",
    "    def __init__(self, action_size,\n",
    "                 board_input_shape=(8,8,6),\n",
    "                 n_conv_channels=12,\n",
    "                 dropout_rate=0.5,\n",
    "                 pi_weight=300.0):\n",
    "        \n",
    "        super(SimpleChessNet, self).__init__()\n",
    "        \n",
    "        self.board_x, self.board_y, self.board_channels = board_input_shape\n",
    "        self.action_size = action_size\n",
    "        self.pi_weight = tf.constant(pi_weight)\n",
    "        \n",
    "        self.input_layer = Input(shape=board_input_shape)\n",
    "        \n",
    "        \n",
    "        h_conv1 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(self.input_layer))) # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(h_conv1)))          # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv2)))         # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv3)))         # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)\n",
    "        \n",
    "        s_fc1 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        \n",
    "        # get the policy and value estimates:\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2) # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)\n",
    "        \n",
    "        self.model = Model(inputs=self.input_layer, outputs=[self.pi, self.v])\n",
    "        # self.model.compile(loss=['categorical_crossentropy', 'mean_squared_error'], optimizer=Adam(learning_rate))\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def compute_loss(self, x, pi, v):\n",
    "        policy_pred, v_pred = self.__call__(x)\n",
    "        v_loss = tf.reduce_mean((v_pred - v)**2)\n",
    "        pi_loss = tf.reduce_mean(-pi*tf.math.log(policy_pred))\n",
    "        total_loss = v_loss + self.pi_weight*pi_loss #tf.add_n([(v_loss + pi_loss)] + self.losses)\n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self.model, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e41a68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 8, 8, 6)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 12)     648         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 12)    48          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 8, 8, 12)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 12)     1296        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 12)    48          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 8, 12)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 6, 6, 12)     1296        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 6, 12)    48          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 6, 6, 12)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 4, 4, 12)     1296        ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 4, 4, 12)    48          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 12)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 192)          0           ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024)         196608      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 1024)        4096        ['dense_8[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 1024)         0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 1024)         0           ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 512)          524288      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 512)         2048        ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 512)          0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 512)          0           ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " pi (Dense)                     (None, 4096)         2101248     ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " v (Dense)                      (None, 1)            513         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,833,529\n",
      "Trainable params: 2,830,361\n",
      "Non-trainable params: 3,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleChessNet(action_size=64*64)\n",
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "class ChessNetModule(tf.Module):\n",
    "    \n",
    "    def __init__(self, learning_rate=1e-5):\n",
    "        super(ChessNetModule, self).__init__()\n",
    "        self.model = SimpleChessNet(action_size=64*64)\n",
    "        self.optimizer = Adam(learning_rate)\n",
    "        self.checkpoint = tf.train.Checkpoint(self.model)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6])])\n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6], tf.float32), \n",
    "                                  tf.TensorSpec([None,64*64], tf.float32), \n",
    "                                  tf.TensorSpec([None], tf.float32)])\n",
    "    def train_step(self, x, pi, v):\n",
    "        with tf.GradientTape() as tape:\n",
    "            v_loss, pi_loss, total_loss = self.model.compute_loss(x, pi, v)\n",
    "        \n",
    "        grads = tape.gradient(total_loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,8,8,6], tf.float32), \n",
    "                                  tf.TensorSpec([None,64*64], tf.float32), \n",
    "                                  tf.TensorSpec([None], tf.float32)])\n",
    "    def validate_step(self, x, pi, v):\n",
    "            v_loss, pi_loss, total_loss = self.model.compute_loss(x, pi, v)\n",
    "            return v_loss, pi_loss, total_loss\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.string)])\n",
    "    def save_checkpoint(self, path):\n",
    "        self.checkpoint.write(path)\n",
    "        return path\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.string)])\n",
    "    def reset_optimizer(self, options):\n",
    "        for var in self.optimizer.variables():\n",
    "            var.assign(tf.zeros_like(var))\n",
    "        return options\n",
    "    \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self, path, \n",
    "        signatures={\n",
    "            'chessnet_serve' : \n",
    "                self.__call__.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32)),\n",
    "            'chessnet_train' : \n",
    "                self.train_step.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32),\n",
    "                                                      tf.TensorSpec([None,64*64], tf.float32),\n",
    "                                                      tf.TensorSpec([None], tf.float32)),\n",
    "            'chessnet_validate' : \n",
    "                self.validate_step.get_concrete_function(tf.TensorSpec([None,8,8,6], tf.float32),\n",
    "                                                      tf.TensorSpec([None,64*64], tf.float32),\n",
    "                                                      tf.TensorSpec([None], tf.float32)),\n",
    "            'chessnet_save_checkpoint':\n",
    "                self.save_checkpoint.get_concrete_function(tf.TensorSpec([], tf.string)),\n",
    "            'chessnet_reset_optimizer':\n",
    "                self.reset_optimizer.get_concrete_function(tf.TensorSpec([], tf.string)),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e92ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SimpleChessNet object at 0x7f987dc6c430>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: simple_chess_net/assets\n"
     ]
    }
   ],
   "source": [
    "nn_mod = ChessNetModule()\n",
    "nn_mod.save('simple_chess_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41118c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

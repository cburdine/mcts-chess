{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ada7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c620c",
   "metadata": {},
   "source": [
    "## MCTS Chess Neural Network\n",
    "---\n",
    "\n",
    "[notes go here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe4a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "class SimpleChessNet():\n",
    "    \n",
    "    def __init__(self, action_size, \n",
    "                 board_input_shape=(8,8,6), \n",
    "                 n_conv_channels=12, \n",
    "                 dropout_rate=0.5,\n",
    "                 learning_rate=1e-3):\n",
    "        \n",
    "        self.board_x, self.board_y, self.board_channels = board_input_shape\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.input_layer = Input(shape=board_input_shape)\n",
    "        \n",
    "        h_conv1 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(self.input_layer))) # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='same', use_bias=False)(h_conv1)))          # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv2)))         # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('elu')(BatchNormalization(axis=3)(Conv2D(n_conv_channels, 3, padding='valid', use_bias=False)(h_conv3)))         # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)\n",
    "        \n",
    "        s_fc1 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(dropout_rate)(Activation('elu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        \n",
    "        # get the policy and value estimates:\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2) # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)\n",
    "        \n",
    "        self.model = Model(inputs=self.input_layer, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy', 'mean_squared_error'], optimizer=Adam(learning_rate))\n",
    "        \n",
    "    def save(self, path):\n",
    "        tf.saved_model.save(self.model, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e41a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8, 8, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 12)     648         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 12)     48          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 12)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 12)     1296        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 12)     48          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 12)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 6, 12)     1296        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6, 6, 12)     48          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 6, 6, 12)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 12)     1296        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 12)     48          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 12)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 192)          0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         196608      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1024)         4096        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1024)         0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          524288      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512)          2048        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pi (Dense)                      (None, 4096)         2101248     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            513         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,833,529\n",
      "Trainable params: 2,830,361\n",
      "Non-trainable params: 3,168\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: simple_chess_net/assets\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleChessNet(action_size=64*64)\n",
    "nn.model.summary()\n",
    "nn.save('simple_chess_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92ae11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
